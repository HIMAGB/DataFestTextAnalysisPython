{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#505050 size=3 face='arial black'>\n",
    "<br><br><center><font color=#505050 size=14 face='arial black'>Topic Models in Python</font></center>  <br><br><center><font color=#13577F size=5 face='arial black'>Kareem Carr</font></center><br><br><br><br>\n",
    "\n",
    "<p>Python is a powerful programming language that's especially suited to text analysis. In this workshop, we will cover some of the most state of the art packages in python for processing text.</p>\n",
    "\n",
    "<p>These packages are much less developed. They require a higher tolerance for non-intuitive interfaces and experimental, incomplete or imperfect features. However, if you stick with it, you can do many very cool things.</p>\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#505050 size=3 face='arial black'>\n",
    "<p><font color=#13577F size=4 face='arial black'> Outline of Latent Dirichlet Allocation-based Topic Modeling </font></p>\n",
    "\n",
    "<p><font color=#13577F size=3 face='arial black'>Topic models</font> are statistical models for learning the hidden structure in document collections.</p>\n",
    "\n",
    "<p><font color=#13577F size=3 face='arial black'>Latent dirichlet allocation</font> and its extensions are a popular class of topic models (Blei et al. 2003). Each document is considered to a mixture of topics. Each topic is defined by the probability of observing certain words. It's more likely one would observe the word 'ball' in a document where the topic is sport than it is to observe the same word in a document where the topic is politics. </p>\n",
    "\n",
    "<br>\n",
    "\n",
    "<figure>\n",
    "    <img src='topics.png' alt='[missing figure]'/>\n",
    "    <figcaption> <center> <font color=#505050 size=2 face='arial black'>Illustration of LDA topic model</font> </center> </figcaption>\n",
    "</figure>\n",
    "\n",
    "<br>\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><font color=#13577F size=4 face='arial black'> What kind of text do you have and where is it located?</font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><font color=#13577F size=4 face='arial black'> Case Study: HTML </font></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<!DOCTYPE html>\\n<html class=\"client-nojs\" lang=\"en\" dir=\"ltr\">\\n<head>\\n<meta charset=\"UTF-8\"/>\\n<title>Python (programming language) - Wikipedia</title>\\n<script>document.documentElement.className = docu'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "wikipedia = urlopen('https://en.wikipedia.org/wiki/Python_(programming_language)')\n",
    "wikipedia_html = wikipedia.read()\n",
    "wikipedia_html[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      "   \n",
      " \n",
      " \n",
      " \n",
      "  CentralNotice  \n",
      " \n",
      " \n",
      " \n",
      " Python (programming language) \n",
      " \n",
      " From Wikipedia, the free encyclopedia \n",
      " \n",
      " \n",
      "\t\t\t\t\tJump to:\t\t\t\t\t navigation , \t\t\t\t\t search \n",
      " \n",
      " \n",
      " Python \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " Paradigm \n",
      " multi-\n"
     ]
    }
   ],
   "source": [
    "#http://stackoverflow.com/questions/1936466/beautifulsoup-grab-visible-webpage-text\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def visible(element):\n",
    "    if element.parent.name in ['style', 'script', '[document]', 'head', 'title']:\n",
    "        return False\n",
    "    elif re.match('<!--.*-->', str(element)):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def clean_html(html):\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    texts = soup.findAll(text=True)\n",
    "    visible_texts = filter(visible,texts)\n",
    "    text = \" \".join(visible_texts)\n",
    "    return(text)\n",
    "\n",
    "cleaned_html = clean_html(wikipedia_html)\n",
    "print(cleaned_html[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><font color=#13577F size=4 face='arial black'> Case Study: Trawling a folder for text files </font></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "example_datasource = os.path.join(current_dir, 'example_datasource' )\n",
    "print(current_dir)\n",
    "print(example_datasource)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "text_files = []\n",
    "\n",
    "for path,dirs, files in os.walk(example_datasource):\n",
    "    for file in files:\n",
    "        if file.endswith('txt'):\n",
    "            text_files.append(os.path.join(path,file))\n",
    "            \n",
    "print(text_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#505050 size=3 face='arial black'>\n",
    "<p><font color=#13577F size=4 face='arial black'> How to Clean Text</font></p>\n",
    "\n",
    "<p> Raw text often contains meta data such as the document name, chapter denotations and names of speakers such as in a play or transcript, along with boilerplate such as declarations of copyright or trademark.\n",
    "</p>\n",
    "\n",
    "<p> The solution to these challenges is a combination of specialized parsers, regular expressions, removing data from fixed locations. </p>\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><font color=#13577F size=4 face='arial black'> 1. Inspect the files </font></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alice_file = open('alice_in_wonderland.txt','r')\n",
    "raw_text = alice_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Gutenberg’s Alice’s Adventures in Wonderland, by Lewis Carroll\n",
      "\n",
      "This eBook is for the use of anyone anywhere at no cost and with\n",
      "almost no restrictions whatsoever.  You may copy it, give it away or\n",
      "re-use it under the terms of the Project Gutenberg License included\n",
      "with this eBook or online at www.gutenberg.org\n",
      "\n",
      "\n",
      "Title: Alice’s Adventures in Wonderland\n",
      "\n",
      "Author: Lewis Carroll\n",
      "\n",
      "Posting Date: June 25, 2008 [EBook #11]\n",
      "Release Date: March, 1994\n",
      "Last Updated: October 6, 2016\n",
      "\n",
      "Language: English\n",
      "\n",
      "Character set encoding: UTF-8\n",
      "\n",
      "*** START OF THIS PROJECT GUTENBERG EBOOK ALICE’S ADVENTURES IN WONDERLAND ***\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ALICE’S ADVENTURES IN WONDERLAND\n",
      "\n",
      "Lewis Carroll\n",
      "\n",
      "THE MILLENNIUM FULCRUM EDITION 3.0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "CHAPTER I. Down the Rabbit-Hole\n",
      "\n",
      "Alice was beginning to get very tired of sitting by her \n"
     ]
    }
   ],
   "source": [
    "#starts with meta data\n",
    "print(raw_text[:800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g Web pages for current donation\n",
      "methods and addresses.  Donations are accepted in a number of other\n",
      "ways including checks, online payments and credit card donations.\n",
      "To donate, please visit: http://pglaf.org/donate\n",
      "\n",
      "\n",
      "Section 5.  General Information About Project Gutenberg-tm electronic\n",
      "works.\n",
      "\n",
      "Professor Michael S. Hart is the originator of the Project Gutenberg-tm\n",
      "concept of a library of electronic works that could be freely shared\n",
      "with anyone.  For thirty years, he produced and distributed Project\n",
      "Gutenberg-tm eBooks with only a loose network of volunteer support.\n",
      "\n",
      "\n",
      "Project Gutenberg-tm eBooks are often created from several printed\n",
      "editions, all of which are confirmed as Public Domain in the U.S.\n",
      "unless a copyright notice is included.  Thus, we do not necessarily\n",
      "keep eBooks in compliance with any particular paper edition.\n",
      "\n",
      "\n",
      "Most people start at our Web site which has the main PG search facility:\n",
      "\n",
      "     http://www.gutenberg.org\n",
      "\n",
      "This Web site includes information about Project Gutenberg-tm,\n",
      "including how to make donations to the Project Gutenberg Literary\n",
      "Archive Foundation, how to help produce our new eBooks, and how to\n",
      "subscribe to our email newsletter to hear about new eBooks.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#ends with legal language\n",
    "print(raw_text[-1200:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><font color=#13577F size=4 face='arial black'> 2. Extract the context you are interested in </font></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "#locate in the text the first occurence of <term> followed by a colon and extract the data after the colon\n",
    "def _get_term(term, text):\n",
    "    result = re.search(term+':.*',text)\n",
    "    if result:\n",
    "        return result.group()[len(term)+1:].strip()\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "author   = _get_term('Author',raw_text)\n",
    "title    = _get_term('Title',raw_text)\n",
    "language = _get_term('Language',raw_text)\n",
    "        \n",
    "preamble, body = re.split('\\*\\*\\* START OF THIS PROJECT GUTENBERG EBOOK.*',raw_text)\n",
    "\n",
    "alice,boilerplate = body[:-18765],body[-18765:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lewis Carroll\n",
      "Alice’s Adventures in Wonderland\n",
      "English\n"
     ]
    }
   ],
   "source": [
    "#meta data\n",
    "print(author,title,language,sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ALICE’S ADVENTURES IN WONDERLAND\n",
      "\n",
      "Lewis Carroll\n",
      "\n",
      "THE MILLENNIUM FULCRUM EDITION 3.0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "CHAPTER I. Down the Rabbit-Hole\n",
      "\n",
      "Alice was beginning to get very tired of sitting by her sister on the\n",
      "bank, and of having nothing to do: once or twice she had peeped into the\n",
      "book her sister was reading, but it had no pictures or conversations in\n",
      "it, ‘and what is the use of a book,’ thought Alice ‘without pictures or\n",
      "conversations?’\n",
      "\n",
      "So she was considering in her own mind (as well as she could, fo\n"
     ]
    }
   ],
   "source": [
    "print(alice[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><font color=#13577F size=4 face='arial black'> 3. Standardize and Transform </font></p>\n",
    "\n",
    "<font color=#505050 size=3 face='arial black'>\n",
    "<ul>\n",
    "<li>tokenization</li>\n",
    "<li>stopword removal</li>\n",
    "<li>normalization</li>\n",
    "<li>collation discovery </li>\n",
    "</ul>\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, ‘and what is the use of a book,’ thought Alice ‘without pictures or conversations?’\n"
     ]
    }
   ],
   "source": [
    "paragraph= \"\"\"Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, ‘and what is the use of a book,’ thought Alice ‘without pictures or conversations?’\"\"\"\n",
    "print(paragraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><font color=#13577F size=3 face='arial black'> Tokenization </font></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alice', 'was', 'beginning', 'to', 'get', 'very', 'tired', 'of', 'sitting', 'by', 'her', 'sister', 'on', 'the', 'bank', 'and', 'of', 'having', 'nothing', 'to', 'do', 'once', 'or', 'twice', 'she', 'had', 'peeped', 'into', 'the', 'book', 'her', 'sister', 'was', 'reading', 'but', 'it', 'had', 'no', 'pictures', 'or', 'conversations', 'in', 'it', 'and', 'what', 'is', 'the', 'use', 'of', 'a', 'book', 'thought', 'Alice', 'without', 'pictures', 'or', 'conversations']\n"
     ]
    }
   ],
   "source": [
    "from nltk import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+').tokenize\n",
    "tokenized_text = tokenizer(paragraph)\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><font color=#13577F size=3 face='arial black'> Stopword removal </font></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/kareemcarr/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', 'couldn', 'didn', 'doesn', 'hadn', 'hasn', 'haven', 'isn', 'ma', 'mightn', 'mustn', 'needn', 'shan', 'shouldn', 'wasn', 'weren', 'won', 'wouldn']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stopword_list = list(stopwords.words('english'))\n",
    "print(stopword_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alice', 'beginning', 'get', 'tired', 'sitting', 'sister', 'bank', 'nothing', 'twice', 'peeped', 'book', 'sister', 'reading', 'pictures', 'conversations', 'use', 'book', 'thought', 'Alice', 'without', 'pictures', 'conversations']\n"
     ]
    }
   ],
   "source": [
    "tokenized_text = [word for word in tokenized_text  if word not in set(stopword_list)]\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><font color=#13577F size=3 face='arial black'> More filtering </font></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat', 'dog', 'mouse']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def has_no_numbers(inputString):\n",
    "     return not any(char.isdigit() for char in inputString)\n",
    "\n",
    "def filter_numbers_from_word_list(word_list):\n",
    "    return list(filter(has_no_numbers, word_list))\n",
    "\n",
    "filter_numbers_from_word_list(['cat','k33p','dog','mouse','1221'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><font color=#13577F size=3 face='arial black'> Extremely stringent filtering </font></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyenchant in /Users/kareemcarr/anaconda/lib/python3.5/site-packages\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['cat', 'dog', 'mouse']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pip\n",
    "pip.main(['install', 'pyenchant'])\n",
    "\n",
    "import enchant\n",
    "eng = enchant.Dict(\"en_US\")\n",
    "eng.check(\"Apple\")\n",
    "\n",
    "list(filter(eng.check,['cat','k33p','dog','mouse','CGIS','Knafel','IQSS']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><font color=#13577F size=3 face='arial black'> Normalization </font></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['president', 'president', 'president']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#simple normalization\n",
    "words = ['President','PRESIDENT','president']\n",
    "[word.lower() for word in words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#505050 size=3 face='arial black'>\n",
    "\n",
    "<p> <font color=#13577F size=3 face='arial black'> Stemming </font> is the process of reducing inflected words to their stem, base or root form </p>\n",
    "\n",
    "<p> <font color=#13577F size=3 face='arial black'> Lemmatisation </font> is the process of grouping together the different inflected forms of a word so they can be analysed as a single item.</p>\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'presid'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "porter_stemmer = PorterStemmer().stem\n",
    "porter_stemmer('president')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "president\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer().lemmatize\n",
    "\n",
    "print(wordnet_lemmatizer('president'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#505050 size=3 face='arial black'>\n",
    "<p><font color=#13577F size=3 face='arial black'> Collation discovery: n-grams </font></p>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import bigrams, ngrams\n",
    "tokens = tokenizer('I had a cat. I had a rat. I had a bat.')\n",
    "bgs = bigrams(tokens)\n",
    "bgs=list(bgs)\n",
    "\n",
    "tgs = ngrams(tokens,n=3)\n",
    "tgs = list(tgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'had'), ('had', 'a'), ('a', 'cat'), ('cat', 'I'), ('I', 'had'), ('had', 'a'), ('a', 'rat'), ('rat', 'I'), ('I', 'had'), ('had', 'a'), ('a', 'bat')]\n"
     ]
    }
   ],
   "source": [
    "print(bgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'had', 'a'), ('had', 'a', 'cat'), ('a', 'cat', 'I'), ('cat', 'I', 'had'), ('I', 'had', 'a'), ('had', 'a', 'rat'), ('a', 'rat', 'I'), ('rat', 'I', 'had'), ('I', 'had', 'a'), ('had', 'a', 'bat')]\n"
     ]
    }
   ],
   "source": [
    "print(tgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({('I', 'had'): 3,\n",
       "          ('a', 'bat'): 1,\n",
       "          ('a', 'cat'): 1,\n",
       "          ('a', 'rat'): 1,\n",
       "          ('cat', 'I'): 1,\n",
       "          ('had', 'a'): 3,\n",
       "          ('rat', 'I'): 1})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.FreqDist(bgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({('I', 'had', 'a'): 3,\n",
       "          ('a', 'cat', 'I'): 1,\n",
       "          ('a', 'rat', 'I'): 1,\n",
       "          ('cat', 'I', 'had'): 1,\n",
       "          ('had', 'a', 'bat'): 1,\n",
       "          ('had', 'a', 'cat'): 1,\n",
       "          ('had', 'a', 'rat'): 1,\n",
       "          ('rat', 'I', 'had'): 1})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.FreqDist(tgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#505050 size=3 face='arial black'>\n",
    "<p><font color=#13577F size=4 face='arial black'> Topic Modeling </font></p>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>play</th>\n",
       "      <th>act</th>\n",
       "      <th>index</th>\n",
       "      <th>speaker</th>\n",
       "      <th>dialogue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Henry IV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACT I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Henry IV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SCENE I. London. The palace.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Henry IV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Enter KING HENRY, LORD JOHN OF LANCASTER, the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Henry IV</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1.1</td>\n",
       "      <td>KING HENRY IV</td>\n",
       "      <td>So shaken as we are, so wan with care,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Henry IV</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1.2</td>\n",
       "      <td>KING HENRY IV</td>\n",
       "      <td>Find we a time for frighted peace to pant,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Henry IV</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1.3</td>\n",
       "      <td>KING HENRY IV</td>\n",
       "      <td>And breathe short-winded accents of new broils</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       play  act  index        speaker  \\\n",
       "1  Henry IV  NaN    NaN            NaN   \n",
       "2  Henry IV  NaN    NaN            NaN   \n",
       "3  Henry IV  NaN    NaN            NaN   \n",
       "4  Henry IV  1.0  1.1.1  KING HENRY IV   \n",
       "5  Henry IV  1.0  1.1.2  KING HENRY IV   \n",
       "6  Henry IV  1.0  1.1.3  KING HENRY IV   \n",
       "\n",
       "                                            dialogue  \n",
       "1                                              ACT I  \n",
       "2                       SCENE I. London. The palace.  \n",
       "3  Enter KING HENRY, LORD JOHN OF LANCASTER, the ...  \n",
       "4             So shaken as we are, so wan with care,  \n",
       "5         Find we a time for frighted peace to pant,  \n",
       "6     And breathe short-winded accents of new broils  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "shakespeare = pd.read_csv('will_play_text.data',delimiter=';',index_col=0,names=['play','act','index','speaker','dialogue'])\n",
    "shakespeare.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>play</th>\n",
       "      <th>act</th>\n",
       "      <th>index</th>\n",
       "      <th>speaker</th>\n",
       "      <th>dialogue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Henry IV</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1.1</td>\n",
       "      <td>KING HENRY IV</td>\n",
       "      <td>So shaken as we are, so wan with care,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Henry IV</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1.2</td>\n",
       "      <td>KING HENRY IV</td>\n",
       "      <td>Find we a time for frighted peace to pant,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Henry IV</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1.3</td>\n",
       "      <td>KING HENRY IV</td>\n",
       "      <td>And breathe short-winded accents of new broils</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Henry IV</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1.4</td>\n",
       "      <td>KING HENRY IV</td>\n",
       "      <td>To be commenced in strands afar remote.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Henry IV</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1.5</td>\n",
       "      <td>KING HENRY IV</td>\n",
       "      <td>No more the thirsty entrance of this soil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Henry IV</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1.6</td>\n",
       "      <td>KING HENRY IV</td>\n",
       "      <td>Shall daub her lips with her own children's bl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       play  act  index        speaker  \\\n",
       "4  Henry IV  1.0  1.1.1  KING HENRY IV   \n",
       "5  Henry IV  1.0  1.1.2  KING HENRY IV   \n",
       "6  Henry IV  1.0  1.1.3  KING HENRY IV   \n",
       "7  Henry IV  1.0  1.1.4  KING HENRY IV   \n",
       "8  Henry IV  1.0  1.1.5  KING HENRY IV   \n",
       "9  Henry IV  1.0  1.1.6  KING HENRY IV   \n",
       "\n",
       "                                            dialogue  \n",
       "4             So shaken as we are, so wan with care,  \n",
       "5         Find we a time for frighted peace to pant,  \n",
       "6     And breathe short-winded accents of new broils  \n",
       "7            To be commenced in strands afar remote.  \n",
       "8          No more the thirsty entrance of this soil  \n",
       "9  Shall daub her lips with her own children's bl...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakespeare = shakespeare[shakespeare['speaker'].notnull()]\n",
    "shakespeare.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>dialogue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KING HENRY IV</td>\n",
       "      <td>So shaken as we are, so wan with care,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KING HENRY IV</td>\n",
       "      <td>Find we a time for frighted peace to pant,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KING HENRY IV</td>\n",
       "      <td>And breathe short-winded accents of new broils</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KING HENRY IV</td>\n",
       "      <td>To be commenced in strands afar remote.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KING HENRY IV</td>\n",
       "      <td>No more the thirsty entrance of this soil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KING HENRY IV</td>\n",
       "      <td>Shall daub her lips with her own children's bl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         speaker                                           dialogue\n",
       "4  KING HENRY IV             So shaken as we are, so wan with care,\n",
       "5  KING HENRY IV         Find we a time for frighted peace to pant,\n",
       "6  KING HENRY IV     And breathe short-winded accents of new broils\n",
       "7  KING HENRY IV            To be commenced in strands afar remote.\n",
       "8  KING HENRY IV          No more the thirsty entrance of this soil\n",
       "9  KING HENRY IV  Shall daub her lips with her own children's bl..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakespeare = shakespeare[['speaker','dialogue']]\n",
    "shakespeare.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "speaker\n",
       "A Lord                                            Sir, it was I.\n",
       "A Patrician    This man has marr'd his fortune. You do the no...\n",
       "A Player       So please your lordship to accept our duty. I ...\n",
       "AARON          Now climbeth Tamora Olympus' top, Safe out of ...\n",
       "ABERGAVENNY    I cannot tell What heaven hath given him,--let...\n",
       "dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speech = shakespeare.groupby('speaker').apply(lambda x: \" \".join(x['dialogue']))\n",
    "speech.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialogue</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speaker</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A Lord</th>\n",
       "      <td>Sir, it was I.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A Patrician</th>\n",
       "      <td>This man has marr'd his fortune. You do the no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A Player</th>\n",
       "      <td>So please your lordship to accept our duty. I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AARON</th>\n",
       "      <td>Now climbeth Tamora Olympus' top, Safe out of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABERGAVENNY</th>\n",
       "      <td>I cannot tell What heaven hath given him,--let...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABHORSON</th>\n",
       "      <td>Do you call, sir? A bawd, sir? fie upon him! h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABRAHAM</th>\n",
       "      <td>Do you bite your thumb at us, sir? Do you bite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACHILLES</th>\n",
       "      <td>Why, how now, Ajax! wherefore do you thus? How...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADAM</th>\n",
       "      <td>Yonder comes my master, your brother. Sweet ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADRIAN</th>\n",
       "      <td>Though this island seem to be desert,-- Uninha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADRIANA</th>\n",
       "      <td>Neither my husband nor the slave return'd, Tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADRIANO DE ARMADO</th>\n",
       "      <td>Boy, what sign is it when a man of great spiri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AEGEON</th>\n",
       "      <td>Proceed, Solinus, to procure my fall And by th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AEMELIA</th>\n",
       "      <td>Be quiet, people. Wherefore throng you hither?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AEMILIUS</th>\n",
       "      <td>Arm, arm, my lord;--Rome never had more cause....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AENEAS</th>\n",
       "      <td>How now, Prince Troilus! wherefore not afield?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AEdile</th>\n",
       "      <td>Peace, peace! He's coming. With old Menenius, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGAMEMNON</th>\n",
       "      <td>Princes, What grief hath set the jaundice on y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGRIPPA</th>\n",
       "      <td>Give me leave, Caesar,-- Thou hast a sister by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AJAX</th>\n",
       "      <td>Thersites! Thersites! Dog! Thou bitch-wolf's s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALBANY</th>\n",
       "      <td>Pray, sir, be patient. My lord, I am guiltless...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALCIBIADES</th>\n",
       "      <td>Sir, you have saved my longing, and I feed Mos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALENCON</th>\n",
       "      <td>They want their porridge and their fat bull-be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALEXANDER</th>\n",
       "      <td>Queen Hecuba and Helen. Up to the eastern towe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALEXAS</th>\n",
       "      <td>Soothsayer! Show him your hand. Enter DOMITIUS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALICE</th>\n",
       "      <td>Un peu, madame. La main? elle est appelee de h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALL</th>\n",
       "      <td>Welcome, high prince, the mighty Duke of York!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALONSO</th>\n",
       "      <td>Good boatswain, have care. Where's the master?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMIENS</th>\n",
       "      <td>Happy is your grace, That can translate the st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANDROMACHE</th>\n",
       "      <td>When was my lord so much ungently temper'd, To...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VIOLA</th>\n",
       "      <td>What country, friends, is this? And what shoul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VIRGILIA</th>\n",
       "      <td>But had he died in the business, madam; how th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VOLTIMAND</th>\n",
       "      <td>In that and all things will we show our duty. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VOLUMNIA</th>\n",
       "      <td>I pray you, daughter, sing; or express yoursel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VOLUMNIUS</th>\n",
       "      <td>What says my lord? Not so, my lord. That's not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vintner</th>\n",
       "      <td>What, standest thou still, and hearest such a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volsce</th>\n",
       "      <td>It is so, sir: truly, I have forgot you. Nican...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WARWICK</th>\n",
       "      <td>Between two hawks, which flies the higher pitc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WESTMORELAND</th>\n",
       "      <td>My liege, this haste was hot in question, And ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WHITMORE</th>\n",
       "      <td>I lost mine eye in laying the prize aboard, An...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WILLIAM</th>\n",
       "      <td>Good even, Audrey. And good even to you, sir. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WILLIAM PAGE</th>\n",
       "      <td>Two. Pulcher. A stone. A pebble. Lapis. Articl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WILLIAM STAFFORD</th>\n",
       "      <td>But angry, wrathful, and inclined to blood, If...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WILLIAMS</th>\n",
       "      <td>We see yonder the beginning of the day, but I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WOODVILE</th>\n",
       "      <td>What noise is this? what traitors have we here...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WORCESTER</th>\n",
       "      <td>Ay, by my faith, that bears a frosty sound.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wall</th>\n",
       "      <td>In this same interlude it doth befall That I, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Watch</th>\n",
       "      <td>[Within]  Qui est la? Enter, go in; the market...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Watchman</th>\n",
       "      <td>We will rather sleep than talk: we know what b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Widow</th>\n",
       "      <td>Nay, come; for if they do approach the city, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wife</th>\n",
       "      <td>Ay, indeed, was he. His wife, an't like your w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YORK</th>\n",
       "      <td>This is my servant: hear him, noble prince. Wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YOUNG CLIFFORD</th>\n",
       "      <td>And so to arms, victorious father, To quell th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YOUNG SIWARD</th>\n",
       "      <td>What is thy name? No; though thou call'st thys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Young LUCIUS</th>\n",
       "      <td>Good grandsire, leave these bitter deep lament...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Young MARCIUS</th>\n",
       "      <td>A' shall not tread on me; I'll run away till I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of BUCKINGHAM</th>\n",
       "      <td>[To KING RICHARD III] The last was I that help...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of King Henry VI</th>\n",
       "      <td>[To KING RICHARD III] When I was mortal, my an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of Prince Edward</th>\n",
       "      <td>[To KING RICHARD III] Let me sit heavy on thy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of young Princes</th>\n",
       "      <td>[To KING RICHARD III] Dream on thy cousins smo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>934 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            dialogue\n",
       "speaker                                                             \n",
       "A Lord                                                Sir, it was I.\n",
       "A Patrician        This man has marr'd his fortune. You do the no...\n",
       "A Player           So please your lordship to accept our duty. I ...\n",
       "AARON              Now climbeth Tamora Olympus' top, Safe out of ...\n",
       "ABERGAVENNY        I cannot tell What heaven hath given him,--let...\n",
       "ABHORSON           Do you call, sir? A bawd, sir? fie upon him! h...\n",
       "ABRAHAM            Do you bite your thumb at us, sir? Do you bite...\n",
       "ACHILLES           Why, how now, Ajax! wherefore do you thus? How...\n",
       "ADAM               Yonder comes my master, your brother. Sweet ma...\n",
       "ADRIAN             Though this island seem to be desert,-- Uninha...\n",
       "ADRIANA            Neither my husband nor the slave return'd, Tha...\n",
       "ADRIANO DE ARMADO  Boy, what sign is it when a man of great spiri...\n",
       "AEGEON             Proceed, Solinus, to procure my fall And by th...\n",
       "AEMELIA            Be quiet, people. Wherefore throng you hither?...\n",
       "AEMILIUS           Arm, arm, my lord;--Rome never had more cause....\n",
       "AENEAS             How now, Prince Troilus! wherefore not afield?...\n",
       "AEdile             Peace, peace! He's coming. With old Menenius, ...\n",
       "AGAMEMNON          Princes, What grief hath set the jaundice on y...\n",
       "AGRIPPA            Give me leave, Caesar,-- Thou hast a sister by...\n",
       "AJAX               Thersites! Thersites! Dog! Thou bitch-wolf's s...\n",
       "ALBANY             Pray, sir, be patient. My lord, I am guiltless...\n",
       "ALCIBIADES         Sir, you have saved my longing, and I feed Mos...\n",
       "ALENCON            They want their porridge and their fat bull-be...\n",
       "ALEXANDER          Queen Hecuba and Helen. Up to the eastern towe...\n",
       "ALEXAS             Soothsayer! Show him your hand. Enter DOMITIUS...\n",
       "ALICE              Un peu, madame. La main? elle est appelee de h...\n",
       "ALL                Welcome, high prince, the mighty Duke of York!...\n",
       "ALONSO             Good boatswain, have care. Where's the master?...\n",
       "AMIENS             Happy is your grace, That can translate the st...\n",
       "ANDROMACHE         When was my lord so much ungently temper'd, To...\n",
       "...                                                              ...\n",
       "VIOLA              What country, friends, is this? And what shoul...\n",
       "VIRGILIA           But had he died in the business, madam; how th...\n",
       "VOLTIMAND          In that and all things will we show our duty. ...\n",
       "VOLUMNIA           I pray you, daughter, sing; or express yoursel...\n",
       "VOLUMNIUS          What says my lord? Not so, my lord. That's not...\n",
       "Vintner            What, standest thou still, and hearest such a ...\n",
       "Volsce             It is so, sir: truly, I have forgot you. Nican...\n",
       "WARWICK            Between two hawks, which flies the higher pitc...\n",
       "WESTMORELAND       My liege, this haste was hot in question, And ...\n",
       "WHITMORE           I lost mine eye in laying the prize aboard, An...\n",
       "WILLIAM            Good even, Audrey. And good even to you, sir. ...\n",
       "WILLIAM PAGE       Two. Pulcher. A stone. A pebble. Lapis. Articl...\n",
       "WILLIAM STAFFORD   But angry, wrathful, and inclined to blood, If...\n",
       "WILLIAMS           We see yonder the beginning of the day, but I ...\n",
       "WOODVILE           What noise is this? what traitors have we here...\n",
       "WORCESTER                Ay, by my faith, that bears a frosty sound.\n",
       "Wall               In this same interlude it doth befall That I, ...\n",
       "Watch              [Within]  Qui est la? Enter, go in; the market...\n",
       "Watchman           We will rather sleep than talk: we know what b...\n",
       "Widow              Nay, come; for if they do approach the city, w...\n",
       "Wife               Ay, indeed, was he. His wife, an't like your w...\n",
       "YORK               This is my servant: hear him, noble prince. Wi...\n",
       "YOUNG CLIFFORD     And so to arms, victorious father, To quell th...\n",
       "YOUNG SIWARD       What is thy name? No; though thou call'st thys...\n",
       "Young LUCIUS       Good grandsire, leave these bitter deep lament...\n",
       "Young MARCIUS      A' shall not tread on me; I'll run away till I...\n",
       "of BUCKINGHAM      [To KING RICHARD III] The last was I that help...\n",
       "of King Henry VI   [To KING RICHARD III] When I was mortal, my an...\n",
       "of Prince Edward   [To KING RICHARD III] Let me sit heavy on thy ...\n",
       "of young Princes   [To KING RICHARD III] Dream on thy cousins smo...\n",
       "\n",
       "[934 rows x 1 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characters = pd.DataFrame()\n",
    "characters['dialogue']=speech\n",
    "characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sir, it was I.', \"This man has marr'd his fortune. You do the nobler. Ay, and burn too. Enter MENENIUS and Senators\"]\n"
     ]
    }
   ],
   "source": [
    "corpus = characters['dialogue'].tolist()\n",
    "print(corpus[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def clean_and_tokenize(raw_text,custom_stopwords=None):\n",
    "    if custom_stopwords == None: custom_stopwords=[] \n",
    "    \n",
    "    #tokenization\n",
    "    tokenizer = RegexpTokenizer(r'\\w+').tokenize\n",
    "    words = tokenizer(raw_text)\n",
    "    \n",
    "    #filters\n",
    "    \n",
    "    #stopwords\n",
    "    words = [word for word in words if word not in set(custom_stopwords+stopword_list)]\n",
    "    \n",
    "    #numbers\n",
    "    words = filter_numbers_from_word_list(words)\n",
    "    \n",
    "    #normalization (stemming)\n",
    "    porter_stemmer = PorterStemmer()\n",
    "    \n",
    "    words = [porter_stemmer.stem(word) for word in words]\n",
    "    \n",
    "    words = [word.lower() for word in words]\n",
    "    \n",
    "    words = [word for word in words if len(word) > 2]\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleaned_corpus = list(map(clean_and_tokenize, corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "call sir bawd sir fie upon discredit mysteri sir mysteri sir mysteri everi true man apparel fit thief littl thief true man think big enough big thief thief think littl enough everi true man apparel fit thief enter provost come bawd instruct thee trade follow sirrah bring barnardin hither what barnardin tell must awak quickli fetch axe upon block sirrah truli sir would desir clap prayer look warrant come look sir come ghostli father jest think enter duke vincentio disguis\n"
     ]
    }
   ],
   "source": [
    "print(\" \".join(cleaned_corpus[5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#505050 size=3 face='arial black'>\n",
    "<p><font color=#13577F size=4 face='arial black'> Topic Models: gensim package</font></p>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /Users/kareemcarr/anaconda/lib/python3.5/site-packages\n",
      "Requirement already satisfied: smart-open>=1.2.1 in /Users/kareemcarr/anaconda/lib/python3.5/site-packages (from gensim)\n",
      "Requirement already satisfied: numpy>=1.3 in /Users/kareemcarr/anaconda/lib/python3.5/site-packages (from gensim)\n",
      "Requirement already satisfied: six>=1.5.0 in /Users/kareemcarr/anaconda/lib/python3.5/site-packages (from gensim)\n",
      "Requirement already satisfied: scipy>=0.7.0 in /Users/kareemcarr/anaconda/lib/python3.5/site-packages (from gensim)\n",
      "Requirement already satisfied: boto>=2.32 in /Users/kareemcarr/anaconda/lib/python3.5/site-packages (from smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied: requests in /Users/kareemcarr/anaconda/lib/python3.5/site-packages (from smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied: bz2file in /Users/kareemcarr/anaconda/lib/python3.5/site-packages (from smart-open>=1.2.1->gensim)\n",
      "'pattern' package not found; tag filters are not available for English\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kareemcarr/anaconda/lib/python3.5/site-packages/gensim/utils.py:1015: UserWarning: Pattern library is not installed, lemmatization won't be available.\n",
      "  warnings.warn(\"Pattern library is not installed, lemmatization won't be available.\")\n"
     ]
    }
   ],
   "source": [
    "pip.main(['install', 'gensim'])\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#505050 size=3 face='arial black'>\n",
    "\n",
    "<p>The <font color=#13577F face='arial black'>term frequency</font> in the simplest case is to use the raw frequency of a term in a document. (High if a word occurs a lot in a particular document).</p>\n",
    "\n",
    "<p>The <font color=#13577F face='arial black'>inverse document frequency</font> is related to the inverse fraction of the documents that contain the word. (High if the term occurs rarely.)</p>\n",
    "\n",
    "<p>The <font color=#13577F face='arial black'>term frequency-inverse document frequency (tf-idf)</font> is just the product of these two measures. A term has a high tf–idf weight if it is a high frequency term in the given document and has a low document frequency in the whole collection of documents.</p>\n",
    "\n",
    "<p>This transformation natural downweights stopwords and words similar to stopwords.</p>\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding document #0 to Dictionary(0 unique tokens: [])\n",
      "built Dictionary(13999 unique tokens: ['inexecr', 'alway', 'cockl', 'prief', 'immodest']...) from 934 documents (total 445999 corpus positions)\n",
      "collecting document frequencies\n",
      "PROGRESS: processing document #0\n",
      "calculating IDF weights for 934 documents and 13998 features (238502 matrix non-zeros)\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "dictionary = corpora.Dictionary(cleaned_corpus)\n",
    "vecs = [dictionary.doc2bow(document) for document in cleaned_corpus]\n",
    "\n",
    "from gensim import models\n",
    "tfidf = models.TfidfModel(vecs)\n",
    "tfidf_vecs = tfidf[vecs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using symmetric alpha at 0.3333333333333333\n",
      "using symmetric eta at 0.3333333333333333\n",
      "using serial LDA version on this node\n",
      "running batch LDA training, 3 topics, 1 passes over the supplied corpus of 934 documents, updating model once every 934 documents, evaluating perplexity every 934 documents, iterating 50x with a convergence threshold of 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-23.043 per-word bound, 8644595.3 perplexity estimate based on a held-out corpus of 934 documents with 9523 words\n",
      "PROGRESS: pass 0, at document #934/934\n",
      "topic #0 (0.333): 0.001*\"sir\" + 0.001*\"lord\" + 0.001*\"and\" + 0.001*\"madam\" + 0.001*\"thou\" + 0.001*\"love\" + 0.001*\"know\" + 0.001*\"king\" + 0.001*\"timon\" + 0.001*\"well\"\n",
      "topic #1 (0.333): 0.002*\"thou\" + 0.002*\"and\" + 0.001*\"thee\" + 0.001*\"thi\" + 0.001*\"the\" + 0.001*\"shall\" + 0.001*\"come\" + 0.001*\"sir\" + 0.001*\"love\" + 0.001*\"that\"\n",
      "topic #2 (0.333): 0.002*\"lord\" + 0.002*\"thi\" + 0.001*\"thou\" + 0.001*\"sir\" + 0.001*\"and\" + 0.001*\"king\" + 0.001*\"thee\" + 0.001*\"shall\" + 0.001*\"good\" + 0.001*\"come\"\n",
      "topic diff=1.328788, rho=1.000000\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.ldamodel import LdaModel\n",
    "lda = LdaModel(corpus=tfidf_vecs,id2word=dictionary,num_topics=3,update_every=0,passes=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#13577F face='arial black'>getting the topics</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topics=lda.top_topics(tfidf_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0019144836857934065, 'thou'),\n",
       " (0.0015290445193528049, 'and'),\n",
       " (0.0012956516811382514, 'thee'),\n",
       " (0.0010381593824981712, 'thi'),\n",
       " (0.00099496145255033265, 'the'),\n",
       " (0.00098808924946222902, 'shall'),\n",
       " (0.00095541572018764383, 'come'),\n",
       " (0.0009503643707128906, 'sir'),\n",
       " (0.00089552143630192203, 'love'),\n",
       " (0.00087839237844720638, 'that'),\n",
       " (0.00085936672048703849, 'well'),\n",
       " (0.00085721788953281315, 'good'),\n",
       " (0.00085664173218580331, 'you'),\n",
       " (0.00084361326820827579, 'king'),\n",
       " (0.00083619940634704199, 'let'),\n",
       " (0.0008273345372338724, 'like'),\n",
       " (0.00080057799214420741, 'would'),\n",
       " (0.00078966577203003782, 'but'),\n",
       " (0.00076652829510123277, 'honour'),\n",
       " (0.0007508148135508978, 'lord')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#13577F face='arial black'>getting the scores</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores=list(lda[tfidf_vecs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.22855052802710862), (1, 0.19884786266769566), (2, 0.57260160930519566)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def dict_to_tuple(n,t):\n",
    "    d = defaultdict(float,t)\n",
    "    return [d[key] for key in range(n)]\n",
    "\n",
    "scores=list(map(lambda t: dict_to_tuple(3,t),scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.80324393575143471, 0.099343009306734356, 0.097413054941831029]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#505050 size=3 face='arial black'>\n",
    "<p><font color=#13577F size=4 face='arial black'> Topic Models: scikit-learn</font></p>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3),\n",
    "                             token_pattern=r'\\b\\w+\\b',\n",
    "                             max_features=10000,\n",
    "                             min_df=10,max_df=0.3)\n",
    "\n",
    "transformed_articles = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#505050 size=3 face='arial black'>\n",
    "<p><font color=#13577F size=4 face='arial black'> How to Transform the scikit-learn vectorizer output for use in gensim</font></p>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "tfidf_vecs_scikit = gensim.matutils.Sparse2Corpus(transformed_articles, documents_columns=False)\n",
    "dictionary_scikit = dict((v, k) for k, v in vectorizer.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#505050 size=3 face='arial black'>\n",
    "<p><font color=#13577F size=4 face='arial black'> Fitting LDA in scikit-learn</font></p>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "lda = LatentDirichletAllocation(n_topics=3,doc_topic_prior=10)\n",
    "lda.fit(transformed_articles)\n",
    "scores_scikit = lda.transform(transformed_articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#505050 size=3 face='arial black'>\n",
    "<p><font color=#13577F size=4 face='arial black'> Looking at results</font></p>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" | \".join([feature_names[i]+\",\"+str(topic[i])\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "        print()\n",
    "\n",
    "print(\"\\nTopics in LDA model:\")\n",
    "tf_feature_names = vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##https://github.com/scikit-learn/scikit-learn/issues/6353"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<font color=#505050 size=3 face='arial black'>\n",
    "\n",
    "<p><font color=#13577F size=4 face='arial black'> Categories of bad topics</font></p>\n",
    "\n",
    "<p>\n",
    " <ul>\n",
    "  <li> general and specific words eg. cat, rabbit, conspecific, heterogenous </li>\n",
    "  <li> mixed topics eg. dog, cat, bird, honda, chevrolet, bmw </li>\n",
    "  <li> changed topics eg. reagan, roosevelt, clinton, licoln, honda, chevrolet, bmw </li>\n",
    "  <li> identical topics </li>\n",
    "  <li> cluttered topics eg. vii, vi, x, xiv, xviii </li>\n",
    "  <li> non-sensical topics </li>\n",
    "</ul>\n",
    "</p>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#505050 size=3 face='arial black'>\n",
    "\n",
    "<p><font color=#13577F size=4 face='arial black'> Evaluating topics</font></p>\n",
    "\n",
    "<p>\n",
    " <ul>\n",
    "  <li> topic size (total probability of a topic across documents) </li>\n",
    "  <li> average word length of top words </li>\n",
    "  <li> topic prominence </li>\n",
    "</ul>\n",
    "</p>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scores_scikit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-f12654032de7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores_scikit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'scores_scikit' is not defined"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "Counter(scores_scikit.argmax(axis=1)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores_scikit.sum(axis=0)/scores_scikit.sum()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
