{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#505050 size=3 face='arial black'>\n",
    "<br><br><center><font color=#505050 size=14 face='arial black'>Topic Models in Python</font></center>  <br><br><center><font color=#13577F size=5 face='arial black'>Kareem Carr</font></center><br><br><br><br>\n",
    "\n",
    "<p>Python is a powerful programming language that's especially suited to text analysis. In this workshop, we will cover some of the most state of the art packages in python for processing text. These packages require a tolerance for non-intuitive interfaces and experimental, incomplete or imperfect features. However, if you stick with it, you can do many very cool things.</p>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#505050 size=3 face='arial black'>\n",
    "<p><font color=#13577F size=4 face='arial black'> Outline of Latent Dirichlet Allocation-based Topic Modeling </font></p>\n",
    "\n",
    "<p><font color=#13577F size=3 face='arial black'>Topic models</font> are statistical models for learning the hidden structure in document collections.</p>\n",
    "\n",
    "<p><font color=#13577F size=3 face='arial black'>Latent dirichlet allocation</font> and its extensions are a popular class of topic models (Blei et al. 2003). Each document is considered to a mixture of topics. Each topic is defined by the probability of observing certain words. It's more likely one would observe the word 'ball' in a document where the topic is sport than it is to observe the same word in a document where the topic is politics. </p>\n",
    "\n",
    "<br>\n",
    "\n",
    "<figure>\n",
    "    <img src='topics.png' alt='[missing figure]'/>\n",
    "    <figcaption> <center> <font color=#505050 size=2 face='arial black'>Illustration of LDA topic model</font> </center> </figcaption>\n",
    "</figure>\n",
    "\n",
    "<br>\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><font color=#13577F size=4 face='arial black'> What kind of text do you have and where is it located?</font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><font color=#13577F size=4 face='arial black'> Case Study: HTML </font></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "wikipedia = urlopen('https://en.wikipedia.org/wiki/Python_(programming_language)')\n",
    "wikipedia_html = wikipedia.read()\n",
    "wikipedia_html[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#http://stackoverflow.com/questions/1936466/beautifulsoup-grab-visible-webpage-text\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def visible(element):\n",
    "    if element.parent.name in ['style', 'script', '[document]', 'head', 'title']:\n",
    "        return False\n",
    "    elif re.match('<!--.*-->', str(element)):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def clean_html(html):\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    texts = soup.findAll(text=True)\n",
    "    visible_texts = filter(visible,texts)\n",
    "    text = \" \".join(visible_texts)\n",
    "    return(text)\n",
    "\n",
    "cleaned_html = clean_html(wikipedia_html)\n",
    "print(cleaned_html[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><font color=#13577F size=4 face='arial black'> Case Study: Trawling a folder for text files </font></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "example_datasource = os.path.join(current_dir, 'example_datasource' )\n",
    "print(current_dir)\n",
    "print(example_datasource)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "text_files = []\n",
    "\n",
    "for path,dirs, files in os.walk(example_datasource):\n",
    "    for file in files:\n",
    "        if file.endswith('txt'):\n",
    "            text_files.append(os.path.join(path,file))\n",
    "            \n",
    "print(text_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#505050 size=3 face='arial black'>\n",
    "<p><font color=#13577F size=4 face='arial black'> How to Clean Text</font></p>\n",
    "\n",
    "<p> Raw text often contains meta data such as the document name, chapter denotations and names of speakers such as in a play or transcript, along with boilerplate such as declarations of copyright or trademark or advertisements.\n",
    "</p>\n",
    "\n",
    "<p> The solution to these challenges is a combination of specialized parsers, regular expressions and removing data from fixed locations. </p>\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><font color=#13577F size=4 face='arial black'> 1. Inspect the files </font></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alice_file = open('alice_in_wonderland.txt','r')\n",
    "raw_text = alice_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#starts with meta data\n",
    "print(raw_text[:800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ends with legal language\n",
    "print(raw_text[-1200:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><font color=#13577F size=4 face='arial black'> 2. Extract the context you are interested in </font></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "#locate in the text the first occurence of <term> followed by a colon and extract the data after the colon\n",
    "def _get_term(term, text):\n",
    "    result = re.search(term+':.*',text)\n",
    "    if result:\n",
    "        return result.group()[len(term)+1:].strip()\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "author   = _get_term('Author',raw_text)\n",
    "title    = _get_term('Title',raw_text)\n",
    "language = _get_term('Language',raw_text)\n",
    "        \n",
    "preamble, body = re.split('\\*\\*\\* START OF THIS PROJECT GUTENBERG EBOOK.*',raw_text)\n",
    "\n",
    "alice,boilerplate = body[:-18765],body[-18765:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#meta data\n",
    "print(author,title,language,sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(alice[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><font color=#13577F size=4 face='arial black'> 3. Standardize and Transform </font></p>\n",
    "\n",
    "<font color=#505050 size=3 face='arial black'>\n",
    "<ul>\n",
    "<li>tokenization</li>\n",
    "<li>stopword removal</li>\n",
    "<li>normalization</li>\n",
    "<li>collation discovery </li>\n",
    "</ul>\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "paragraph= \"\"\"Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, ‘and what is the use of a book,’ thought Alice ‘without pictures or conversations?’\"\"\"\n",
    "print(paragraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><font color=#13577F size=3 face='arial black'> Tokenization </font></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+').tokenize\n",
    "tokenized_text = tokenizer(paragraph)\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><font color=#13577F size=3 face='arial black'> Stopword removal </font></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stopword_list = list(stopwords.words('english'))\n",
    "print(stopword_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenized_text = [word for word in tokenized_text  if word not in set(stopword_list)]\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><font color=#13577F size=3 face='arial black'> More filtering </font></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def has_no_numbers(inputString):\n",
    "     return not any(char.isdigit() for char in inputString)\n",
    "\n",
    "def filter_numbers_from_word_list(word_list):\n",
    "    return list(filter(has_no_numbers, word_list))\n",
    "\n",
    "filter_numbers_from_word_list(['cat','k33p','dog','mouse','1221'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><font color=#13577F size=3 face='arial black'> Extremely stringent filtering </font></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pip\n",
    "pip.main(['install', 'pyenchant'])\n",
    "\n",
    "import enchant\n",
    "eng = enchant.Dict(\"en_US\")\n",
    "eng.check(\"Apple\")\n",
    "\n",
    "list(filter(eng.check,['cat','k33p','dog','mouse','CGIS','Knafel','IQSS']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><font color=#13577F size=3 face='arial black'> Normalization </font></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#simple normalization\n",
    "words = ['President','PRESIDENT','president']\n",
    "[word.lower() for word in words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#505050 size=3 face='arial black'>\n",
    "\n",
    "<p> <font color=#13577F size=3 face='arial black'> Stemming </font> is the process of reducing inflected words to their stem, base or root form </p>\n",
    "\n",
    "<p> <font color=#13577F size=3 face='arial black'> Lemmatisation </font> is the process of grouping together the different inflected forms of a word so they can be analysed as a single item.</p>\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "porter_stemmer = PorterStemmer().stem\n",
    "porter_stemmer('president')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer().lemmatize\n",
    "\n",
    "print(wordnet_lemmatizer('president'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#505050 size=3 face='arial black'>\n",
    "<p><font color=#13577F size=3 face='arial black'> Collation discovery: n-grams </font></p>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import bigrams, ngrams\n",
    "tokens = tokenizer('I had a cat. I had a rat. I had a bat.')\n",
    "bgs = bigrams(tokens)\n",
    "bgs=list(bgs)\n",
    "\n",
    "tgs = ngrams(tokens,n=3)\n",
    "tgs = list(tgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(bgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(tgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nltk.FreqDist(bgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nltk.FreqDist(tgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#505050 size=3 face='arial black'>\n",
    "<p><font color=#13577F size=4 face='arial black'> Topic Modeling </font></p>\n",
    "\n",
    "<p>Our example today is a plain text file containing all the lines in each of Shakespeare's plays. It is in a specialized format where each entry is delimited by a semi-colon. We are going to load the data into Python and convert it to corpus where the document will be all the lines spoken by a particular character in any play.\n",
    "</p>\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#505050 size=3 face='arial black'>\n",
    "<p><font color=#13577F size=3 face='arial black'> read data from file </font></p>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>play</th>\n",
       "      <th>act</th>\n",
       "      <th>index</th>\n",
       "      <th>speaker</th>\n",
       "      <th>dialogue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Henry IV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACT I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Henry IV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SCENE I. London. The palace.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Henry IV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Enter KING HENRY, LORD JOHN OF LANCASTER, the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Henry IV</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1.1</td>\n",
       "      <td>KING HENRY IV</td>\n",
       "      <td>So shaken as we are, so wan with care,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Henry IV</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1.2</td>\n",
       "      <td>KING HENRY IV</td>\n",
       "      <td>Find we a time for frighted peace to pant,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Henry IV</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1.3</td>\n",
       "      <td>KING HENRY IV</td>\n",
       "      <td>And breathe short-winded accents of new broils</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       play  act  index        speaker  \\\n",
       "1  Henry IV  NaN    NaN            NaN   \n",
       "2  Henry IV  NaN    NaN            NaN   \n",
       "3  Henry IV  NaN    NaN            NaN   \n",
       "4  Henry IV  1.0  1.1.1  KING HENRY IV   \n",
       "5  Henry IV  1.0  1.1.2  KING HENRY IV   \n",
       "6  Henry IV  1.0  1.1.3  KING HENRY IV   \n",
       "\n",
       "                                            dialogue  \n",
       "1                                              ACT I  \n",
       "2                       SCENE I. London. The palace.  \n",
       "3  Enter KING HENRY, LORD JOHN OF LANCASTER, the ...  \n",
       "4             So shaken as we are, so wan with care,  \n",
       "5         Find we a time for frighted peace to pant,  \n",
       "6     And breathe short-winded accents of new broils  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "shakespeare = pd.read_csv('will_play_text.data',delimiter=';',index_col=0,names=['play','act','index','speaker','dialogue'])\n",
    "shakespeare.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#505050 size=3 face='arial black'>\n",
    "<p><font color=#13577F size=3 face='arial black'> isolate the text for each speaker </font></p>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shakespeare = shakespeare[shakespeare['speaker'].notnull()]\n",
    "shakespeare.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shakespeare = shakespeare[['speaker','dialogue']]\n",
    "shakespeare.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#505050 size=3 face='arial black'>\n",
    "<p><font color=#13577F size=3 face='arial black'> collect and convert to a list </font></p>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "speech = shakespeare.groupby('speaker').apply(lambda x: \" \".join(x['dialogue']))\n",
    "speech.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "characters = pd.DataFrame()\n",
    "characters['dialogue']=speech\n",
    "characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corpus = characters['dialogue'].tolist()\n",
    "print(corpus[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#505050 size=3 face='arial black'>\n",
    "<p><font color=#13577F size=3 face='arial black'> process for topic modeling using the processes we discussed earlier </font></p>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def clean_and_tokenize(raw_text,custom_stopwords=None):\n",
    "    if custom_stopwords == None: custom_stopwords=[] \n",
    "    \n",
    "    #tokenization\n",
    "    tokenizer = RegexpTokenizer(r'\\w+').tokenize\n",
    "    words = tokenizer(raw_text)\n",
    "    \n",
    "    #filters\n",
    "    \n",
    "    #stopwords\n",
    "    words = [word for word in words if word not in set(custom_stopwords+stopword_list)]\n",
    "    \n",
    "    #numbers\n",
    "    words = filter_numbers_from_word_list(words)\n",
    "    \n",
    "    #normalization (stemming)\n",
    "    porter_stemmer = PorterStemmer()\n",
    "    \n",
    "    words = [porter_stemmer.stem(word) for word in words]\n",
    "    \n",
    "    words = [word.lower() for word in words]\n",
    "    \n",
    "    words = [word for word in words if len(word) > 2]\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleaned_corpus = list(map(clean_and_tokenize, corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\" \".join(cleaned_corpus[5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#505050 size=3 face='arial black'>\n",
    "<p><font color=#13577F size=4 face='arial black'> Topic Models: gensim package</font></p>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pip.main(['install', 'gensim'])\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#505050 size=3 face='arial black'>\n",
    "\n",
    "<p>The <font color=#13577F face='arial black'>term frequency</font> in the simplest case is to use the raw frequency of a term in a document. (High if a word occurs a lot in a particular document).</p>\n",
    "\n",
    "<p>The <font color=#13577F face='arial black'>inverse document frequency</font> is related to the inverse fraction of the documents that contain the word. (High if the term occurs rarely.)</p>\n",
    "\n",
    "<p>The <font color=#13577F face='arial black'>term frequency-inverse document frequency (tf-idf)</font> is just the product of these two measures. A term has a high tf–idf weight if it is a high frequency term in the given document and has a low document frequency in the whole collection of documents.</p>\n",
    "\n",
    "<p>This transformation natural downweights stopwords and words similar to stopwords.</p>\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "dictionary = corpora.Dictionary(cleaned_corpus)\n",
    "vecs = [dictionary.doc2bow(document) for document in cleaned_corpus]\n",
    "\n",
    "from gensim import models\n",
    "tfidf = models.TfidfModel(vecs)\n",
    "tfidf_vecs = tfidf[vecs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.models.ldamodel import LdaModel\n",
    "lda = LdaModel(corpus=tfidf_vecs,id2word=dictionary,num_topics=3,update_every=0,passes=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#13577F  size=3 face='arial black'>getting the topics</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topics=lda.top_topics(tfidf_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topics[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#13577F size=3 face='arial black'>getting the scores</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores=list(lda[tfidf_vecs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def dict_to_tuple(n,t):\n",
    "    d = defaultdict(float,t)\n",
    "    return [d[key] for key in range(n)]\n",
    "\n",
    "scores=list(map(lambda t: dict_to_tuple(3,t),scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#505050 size=3 face='arial black'>\n",
    "<p><font color=#13577F size=4 face='arial black'> Topic Models: scikit-learn</font></p>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3),\n",
    "                             token_pattern=r'\\b\\w+\\b',\n",
    "                             max_features=10000,\n",
    "                             min_df=10,max_df=0.3)\n",
    "\n",
    "transformed_articles = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#505050 size=3 face='arial black'>\n",
    "<p><font color=#13577F size=4 face='arial black'> How to Transform the scikit-learn vectorizer output for use in gensim</font></p>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "tfidf_vecs_scikit = gensim.matutils.Sparse2Corpus(transformed_articles, documents_columns=False)\n",
    "dictionary_scikit = dict((v, k) for k, v in vectorizer.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#505050 size=3 face='arial black'>\n",
    "<p><font color=#13577F size=4 face='arial black'> Fitting LDA in scikit-learn</font></p>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "lda = LatentDirichletAllocation(n_topics=3,doc_topic_prior=10)\n",
    "lda.fit(transformed_articles)\n",
    "scores_scikit = lda.transform(transformed_articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#505050 size=3 face='arial black'>\n",
    "<p><font color=#13577F size=4 face='arial black'> Looking at results</font></p>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" | \".join([feature_names[i]+\",\"+str(topic[i])\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "        print()\n",
    "\n",
    "print(\"\\nTopics in LDA model:\")\n",
    "tf_feature_names = vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##https://github.com/scikit-learn/scikit-learn/issues/6353"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<font color=#505050 size=3 face='arial black'>\n",
    "\n",
    "<p><font color=#13577F size=4 face='arial black'> Categories of bad topics</font></p>\n",
    "\n",
    "<p>\n",
    " <ul>\n",
    "  <li> general and specific words eg. cat, rabbit, conspecific, heterogenous </li>\n",
    "  <li> mixed topics eg. dog, cat, bird, honda, chevrolet, bmw </li>\n",
    "  <li> changed topics eg. reagan, roosevelt, clinton, licoln, honda, chevrolet, bmw </li>\n",
    "  <li> identical topics </li>\n",
    "  <li> cluttered topics eg. vii, vi, x, xiv, xviii </li>\n",
    "  <li> non-sensical topics </li>\n",
    "</ul>\n",
    "</p>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#505050 size=3 face='arial black'>\n",
    "\n",
    "<p><font color=#13577F size=4 face='arial black'> Evaluating topics</font></p>\n",
    "\n",
    "<p>\n",
    " <ul>\n",
    "  <li> topic size (total probability of a topic across documents) </li>\n",
    "  <li> average word length of top words </li>\n",
    "  <li> topic prominence </li>\n",
    "</ul>\n",
    "</p>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#topic sie\n",
    "scores_scikit.sum(axis=0)/scores_scikit.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#topic prominence\n",
    "%matplotlib inline\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "Counter(scores_scikit.argmax(axis=1)+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#505050 size=3 face='arial black'>\n",
    "\n",
    "<p>\n",
    "Topic modeling requires continual refinement of the filtering process. You will typically generate the topics, look at the resutls and repeat the process until you find good results.\n",
    "</p>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#505050 size=3 face='arial black'>\n",
    "\n",
    "<p><font color=#13577F size=8 face='arial black'> Thanks!</font></p>\n",
    "\n",
    "</font>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
